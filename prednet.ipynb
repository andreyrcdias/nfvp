{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be8e5c4",
   "metadata": {},
   "source": [
    "## [PredNet](https://coxlab.github.io/prednet/)\n",
    "\n",
    "* https://github.com/coxlab/prednet\n",
    "\n",
    "* [DEEP PREDICTIVE CODING NETWORKS FOR VIDEO PREDICTION AND UNSUPERVISED LEARNING](https://arxiv.org/abs/1605.08104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61786ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib tensorflow imageio ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15dabde",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3661c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "\n",
    "import io\n",
    "import imageio\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, HBox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9987ece",
   "metadata": {},
   "source": [
    "## Dataset Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b7b5da",
   "metadata": {},
   "source": [
    "Loading MovingMNIST dataset from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd37359",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = keras.utils.get_file(\n",
    "    \"moving_mnist.npy\",\n",
    "    \"http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy\",\n",
    ")\n",
    "dataset = np.load(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931e72c8",
   "metadata": {},
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the axes representing the number of frames and number of data samples.\n",
    "dataset = np.swapaxes(dataset, 0, 1)\n",
    "\n",
    "SAMPLES = 1000\n",
    "dataset = dataset[:SAMPLES, ...]\n",
    "\n",
    "# Add a channel dimension since the images are grayscale.\n",
    "dataset = np.expand_dims(dataset, axis=-1)\n",
    "\n",
    "# Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * dataset.shape[0])]\n",
    "val_index = indexes[int(0.9 * dataset.shape[0]) :]\n",
    "train_dataset = dataset[train_index]\n",
    "val_dataset = dataset[val_index]\n",
    "\n",
    "# Normalize to 0-1 range\n",
    "train_dataset = train_dataset / 255\n",
    "val_dataset = val_dataset / 255\n",
    "\n",
    "def create_shifted_frames(data):\n",
    "    # x is frames 0 to n -1\n",
    "    x = data[:, 0 : data.shape[1] - 1, :, :]\n",
    "    # y is frames 1 to n\n",
    "    y = data[:, 1 : data.shape[1], :, :]\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = create_shifted_frames(train_dataset)\n",
    "x_val, y_val = create_shifted_frames(val_dataset)\n",
    "print(f\"Training Dataset Shapes: {str(x_train.shape)}, {str(y_train.shape)}\")\n",
    "print(f\"Validation Dataset Shapes: {str(x_val.shape)}, {str(y_val.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921584f4",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44685d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(10, 8))\n",
    "\n",
    "# Plot each of the sequential images for one random data example.\n",
    "data_choice = np.random.choice(range(len(train_dataset)), size=1)[0]\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    ax.imshow(np.squeeze(train_dataset[data_choice][idx]), cmap=\"gray\")\n",
    "    ax.set_title(f\"Frame {idx + 1}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "print(f\"Displaying frames for example {data_choice}.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975b1dd",
   "metadata": {},
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b47309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential(name=\"PredNet\")\n",
    "\n",
    "    # encoding\n",
    "    model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(None, *x_train.shape[2:])))\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "    # ConvLSTMs\n",
    "    model.add(layers.ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same', return_sequences=True))\n",
    "    model.add(layers.ConvLSTM2D(filters=32, kernel_size=(3, 3), padding='same', return_sequences=True))\n",
    "    model.add(layers.ConvLSTM2D(filters=16, kernel_size=(3, 3), padding='same', return_sequences=True))\n",
    "\n",
    "    # decoding\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=1, kernel_size=(3, 3), padding='same', activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.binary_crossentropy,\n",
    "        # optimizer=keras.optimizers.Adam(),\n",
    "        optimizer=keras.optimizers.legacy.Adam(), # for arm64\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe874312",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20acdc85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 5\n",
    "MODEL_NAME = f\"prednet_{SAMPLES}_{EPOCHS}_{BATCH_SIZE}\"\n",
    "MODEL_PATH = f\"trained/{MODEL_NAME}.h5\"\n",
    "print(MODEL_PATH)\n",
    "\n",
    "# load or create model\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"loading\")\n",
    "    model = load_model(MODEL_PATH)\n",
    "else:\n",
    "    print(\"creating\")\n",
    "    model = create_model()\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=[\n",
    "            # Improve training\n",
    "            keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de32a66",
   "metadata": {},
   "source": [
    "## Frame Prediction Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5aacfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random example from the validation dataset.\n",
    "example = val_dataset[np.random.choice(range(len(val_dataset)), size=1)[0]]\n",
    "\n",
    "# Pick the first/last ten frames from the example.\n",
    "frames = example[:10, ...]\n",
    "original_frames = example[10:, ...]\n",
    "\n",
    "# Predict new 10 frames\n",
    "for _ in range(10):\n",
    "    # Extract the model's prediction and post-process it.\n",
    "    new_prediction = model.predict(np.expand_dims(frames, axis=0))\n",
    "    new_prediction = np.squeeze(new_prediction, axis=0)\n",
    "    predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)\n",
    "\n",
    "    # Extend the set of prediction frames.\n",
    "    frames = np.concatenate((frames, predicted_frame), axis=0)\n",
    "\n",
    "# Construct a figure for the original and new frames.\n",
    "fig, axes = plt.subplots(2, 10, figsize=(20, 4))\n",
    "\n",
    "# Plot the original frames.\n",
    "for idx, ax in enumerate(axes[0]):\n",
    "    ax.imshow(np.squeeze(original_frames[idx]), cmap=\"gray\")\n",
    "    ax.set_title(f\"Frame {idx + 11}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Plot the predicted.\n",
    "new_frames = frames[10:, ...]\n",
    "for idx, ax in enumerate(axes[1]):\n",
    "    ax.imshow(np.squeeze(new_frames[idx]), cmap=\"gray\")\n",
    "    ax.set_title(f\"Frame {idx + 11}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807e66d",
   "metadata": {},
   "source": [
    "## Predicted Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddada252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few random examples from the dataset.\n",
    "examples = val_dataset[np.random.choice(range(len(val_dataset)), size=5)]\n",
    "\n",
    "predicted_videos = []\n",
    "mses, psnrs = []\n",
    "for example in examples:\n",
    "    # Pick the first/last ten frames from the example.\n",
    "    frames = example[:10, ...]\n",
    "    original_frames = example[10:, ...]\n",
    "    new_predictions = np.zeros(shape=(10, *frames[0].shape))\n",
    "\n",
    "    # Predict a new set of 10 frames.\n",
    "    for i in range(10):\n",
    "        # Extract the model's prediction and post-process it.\n",
    "        frames = example[: 10 + i + 1, ...]\n",
    "        new_prediction = model.predict(np.expand_dims(frames, axis=0))\n",
    "        new_prediction = np.squeeze(new_prediction, axis=0)\n",
    "        predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)\n",
    "\n",
    "        # Extend the set of prediction frames.\n",
    "        new_predictions[i] = predicted_frame\n",
    "    \n",
    "    # Metrics\n",
    "    mse = np.mean(np.square(original_frames - new_predictions))\n",
    "    mses.append(mse)\n",
    "    psnr = 10 * np.log10(255**2 / mse)\n",
    "    psnrs.append(psnr)\n",
    "\n",
    "    # Create and save GIFs for each of the ground truth/prediction images.\n",
    "    for frame_set in [original_frames, new_predictions]:\n",
    "        # Construct a GIF from the selected video frames.\n",
    "        current_frames = np.squeeze(frame_set)\n",
    "        current_frames = current_frames[..., np.newaxis] * np.ones(3)\n",
    "        current_frames = (current_frames * 255).astype(np.uint8)\n",
    "        current_frames = list(current_frames)\n",
    "\n",
    "        with io.BytesIO() as gif:\n",
    "            imageio.mimsave(gif, current_frames, \"GIF\", duration=2)\n",
    "            predicted_videos.append(gif.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Truth\\tPrediction\")\n",
    "for i in range(0, len(predicted_videos), 2):\n",
    "    box = HBox(\n",
    "        [\n",
    "            widgets.Image(value=predicted_videos[i]),\n",
    "            widgets.Image(value=predicted_videos[i + 1]),\n",
    "        ]\n",
    "    )\n",
    "    display(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mses)\n",
    "plt.plot(psnrs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
