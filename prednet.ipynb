{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be8e5c4",
   "metadata": {},
   "source": [
    "## [PredNet](https://coxlab.github.io/prednet/)\n",
    "\n",
    "* https://github.com/coxlab/prednet\n",
    "\n",
    "* [DEEP PREDICTIVE CODING NETWORKS FOR VIDEO PREDICTION AND UNSUPERVISED LEARNING](https://arxiv.org/abs/1605.08104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61786ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (3.7.2)\n",
      "Requirement already satisfied: tensorflow in ./.venv/lib/python3.9/site-packages (2.13.0)\n",
      "Requirement already satisfied: imageio in ./.venv/lib/python3.9/site-packages (2.31.1)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.9/site-packages (8.0.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in ./.venv/lib/python3.9/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.56.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in ./.venv/lib/python3.9/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in ./.venv/lib/python3.9/site-packages (from ipywidgets) (6.24.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.9/site-packages (from ipywidgets) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.9/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in ./.venv/lib/python3.9/site-packages (from ipywidgets) (4.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in ./.venv/lib/python3.9/site-packages (from ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: appnope in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (8.3.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.2)\n",
      "Requirement already satisfied: backcall in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./.venv/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in ./.venv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (6.7.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.venv/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./.venv/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in ./.venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./.venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib tensorflow imageio ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15dabde",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3661c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "\n",
    "import io\n",
    "import imageio\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, HBox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9987ece",
   "metadata": {},
   "source": [
    "## Dataset Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b7b5da",
   "metadata": {},
   "source": [
    "Loading MovingMNIST dataset from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd37359",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = keras.utils.get_file(\n",
    "    \"moving_mnist.npy\",\n",
    "    \"http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy\",\n",
    ")\n",
    "dataset = np.load(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931e72c8",
   "metadata": {},
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the axes representing the number of frames and number of data samples.\n",
    "dataset = np.swapaxes(dataset, 0, 1)\n",
    "\n",
    "SAMPLES = 1000\n",
    "dataset = dataset[:SAMPLES, ...]\n",
    "\n",
    "# Add a channel dimension since the images are grayscale.\n",
    "dataset = np.expand_dims(dataset, axis=-1)\n",
    "\n",
    "# Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * dataset.shape[0])]\n",
    "val_index = indexes[int(0.9 * dataset.shape[0]) :]\n",
    "train_dataset = dataset[train_index]\n",
    "val_dataset = dataset[val_index]\n",
    "\n",
    "# Normalize to 0-1 range\n",
    "train_dataset = train_dataset / 255\n",
    "val_dataset = val_dataset / 255\n",
    "\n",
    "def create_shifted_frames(data):\n",
    "    # x is frames 0 to n -1\n",
    "    x = data[:, 0 : data.shape[1] - 1, :, :]\n",
    "    # y is frames 1 to n\n",
    "    y = data[:, 1 : data.shape[1], :, :]\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = create_shifted_frames(train_dataset)\n",
    "x_val, y_val = create_shifted_frames(val_dataset)\n",
    "print(f\"Training Dataset Shapes: {str(x_train.shape)}, {str(y_train.shape)}\")\n",
    "print(f\"Validation Dataset Shapes: {str(x_val.shape)}, {str(y_val.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921584f4",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44685d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(10, 8))\n",
    "\n",
    "# Plot each of the sequential images for one random data example.\n",
    "data_choice = np.random.choice(range(len(train_dataset)), size=1)[0]\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    ax.imshow(np.squeeze(train_dataset[data_choice][idx]), cmap=\"gray\")\n",
    "    ax.set_title(f\"Frame {idx + 1}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "print(f\"Displaying frames for example {data_choice}.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975b1dd",
   "metadata": {},
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b47309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential(name=\"PredNet\")\n",
    "\n",
    "    # encoding\n",
    "    model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(None, *x_train.shape[2:])))\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "    # ConvLSTMs\n",
    "    model.add(layers.ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same', return_sequences=True))\n",
    "    model.add(layers.ConvLSTM2D(filters=32, kernel_size=(3, 3), padding='same', return_sequences=True))\n",
    "    model.add(layers.ConvLSTM2D(filters=16, kernel_size=(3, 3), padding='same', return_sequences=True))\n",
    "\n",
    "    # decoding\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=1, kernel_size=(3, 3), padding='same', activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        # loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(),\n",
    "        # for arm64\n",
    "        loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.legacy.Adam(),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe874312",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20acdc85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 5\n",
    "MODEL_NAME = f\"prednet_{SAMPLES}_{EPOCHS}_{BATCH_SIZE}\"\n",
    "model = create_model()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[\n",
    "        # Improve training\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "    ],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "def save_model(model):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(f\"trained/{MODEL_NAME}.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(f\"trained/{MODEL_NAME}.h5\")\n",
    "    model.save(f\"trained/{MODEL_NAME}.keras\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2795b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    with open(f'trained/{MODEL_NAME}.json', 'r') as json_file:\n",
    "        loaded_model_json = json_file.read()\n",
    "\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(f\"trained/{MODEL_NAME}.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "# load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de32a66",
   "metadata": {},
   "source": [
    "## Frame Prediction Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5aacfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random example from the validation dataset.\n",
    "example = val_dataset[np.random.choice(range(len(val_dataset)), size=1)[0]]\n",
    "\n",
    "# Pick the first/last ten frames from the example.\n",
    "frames = example[:10, ...]\n",
    "original_frames = example[10:, ...]\n",
    "\n",
    "# Predict new 10 frames\n",
    "for _ in range(10):\n",
    "    # Extract the model's prediction and post-process it.\n",
    "    new_prediction = model.predict(np.expand_dims(frames, axis=0))\n",
    "    new_prediction = np.squeeze(new_prediction, axis=0)\n",
    "    predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)\n",
    "\n",
    "    # Extend the set of prediction frames.\n",
    "    frames = np.concatenate((frames, predicted_frame), axis=0)\n",
    "\n",
    "# Construct a figure for the original and new frames.\n",
    "fig, axes = plt.subplots(2, 10, figsize=(20, 4))\n",
    "\n",
    "# Plot the original frames.\n",
    "for idx, ax in enumerate(axes[0]):\n",
    "    ax.imshow(np.squeeze(original_frames[idx]), cmap=\"gray\")\n",
    "    ax.set_title(f\"Frame {idx + 11}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Plot the predicted.\n",
    "new_frames = frames[10:, ...]\n",
    "for idx, ax in enumerate(axes[1]):\n",
    "    ax.imshow(np.squeeze(new_frames[idx]), cmap=\"gray\")\n",
    "    ax.set_title(f\"Frame {idx + 11}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b5e839",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891349b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(original, predicted):\n",
    "    mse = np.mean((original - predicted) ** 2)\n",
    "    max_value = np.max(original)\n",
    "    psnr = 20 * np.log10(max_value / np.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def calculate_mse(original, predicted):\n",
    "    mse = np.mean((original - predicted) ** 2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807e66d",
   "metadata": {},
   "source": [
    "## Predicted Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddada252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few random examples from the dataset.\n",
    "examples = val_dataset[np.random.choice(range(len(val_dataset)), size=5)]\n",
    "\n",
    "predicted_videos = []\n",
    "psnrs = []\n",
    "mses = []\n",
    "for example in examples:\n",
    "    # Pick the first/last ten frames from the example.\n",
    "    frames = example[:10, ...]\n",
    "    original_frames = example[10:, ...]\n",
    "    new_predictions = np.zeros(shape=(10, *frames[0].shape))\n",
    "\n",
    "    # Predict a new set of 10 frames.\n",
    "    for i in range(10):\n",
    "        # Extract the model's prediction and post-process it.\n",
    "        frames = example[: 10 + i + 1, ...]\n",
    "        new_prediction = model.predict(np.expand_dims(frames, axis=0))\n",
    "        new_prediction = np.squeeze(new_prediction, axis=0)\n",
    "        predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)\n",
    "\n",
    "        # Extend the set of prediction frames.\n",
    "        new_predictions[i] = predicted_frame\n",
    "    \n",
    "    # Metrics\n",
    "    psnrs.append(calculate_psnr(original_frames, new_predictions))\n",
    "    mses.append(calculate_mse(original_frames, new_predictions))\n",
    "\n",
    "    # Create and save GIFs for each of the ground truth/prediction images.\n",
    "    for frame_set in [original_frames, new_predictions]:\n",
    "        # Construct a GIF from the selected video frames.\n",
    "        current_frames = np.squeeze(frame_set)\n",
    "        current_frames = current_frames[..., np.newaxis] * np.ones(3)\n",
    "        current_frames = (current_frames * 255).astype(np.uint8)\n",
    "        current_frames = list(current_frames)\n",
    "\n",
    "        # Construct a GIF from the frames.\n",
    "        with io.BytesIO() as gif:\n",
    "            imageio.mimsave(gif, current_frames, \"GIF\", duration=2)\n",
    "            predicted_videos.append(gif.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Truth\\tPrediction\")\n",
    "for i in range(0, len(predicted_videos), 2):\n",
    "    # Construct and display an `HBox` with the ground truth and prediction.\n",
    "    box = HBox(\n",
    "        [\n",
    "            widgets.Image(value=predicted_videos[i]),\n",
    "            widgets.Image(value=predicted_videos[i + 1]),\n",
    "        ]\n",
    "    )\n",
    "    display(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(psnrs)\n",
    "plt.plot(mses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
